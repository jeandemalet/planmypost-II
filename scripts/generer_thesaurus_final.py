import json
from collections import defaultdict

def generer_thesaurus_final(scraped_file="predis_ai_raw.json", 
                          semantic_file="hiertags_relations_raw.jsonl",  # Format JSONL
                          output_file="hashtag-thesaurus.json"):
    """Fusionne les donn√©es scrap√©es et s√©mantiques pour cr√©er le dictionnaire final."""
    
    try:
        with open(scraped_file, 'r', encoding='utf-8') as f:
            scraped_data = json.load(f)
    except FileNotFoundError as e:
        print(f"‚ùå ERREUR: Fichier manquant : {e.filename}. Veuillez d'abord ex√©cuter le script de scraping.")
        return
    
    # Chargement des donn√©es s√©mantiques depuis le fichier JSONL
    print(f"üìä Chargement des donn√©es s√©mantiques depuis '{semantic_file}'...")
    semantic_data = defaultdict(dict)
    
    try:
        with open(semantic_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                if line.strip():  # Ignorer les lignes vides
                    try:
                        rel = json.loads(line)
                        semantic_data[rel['tag']][rel['related']] = rel['weight']
                    except json.JSONDecodeError:
                        print(f"‚ö†Ô∏è Ligne {line_num} ignor√©e (JSON invalide)")
                        continue
        print(f"‚úÖ {len(semantic_data):,} tags avec relations s√©mantiques charg√©s.")
    except FileNotFoundError:
        print(f"‚ö†Ô∏è Fichier '{semantic_file}' non trouv√©. G√©n√©ration sans donn√©es s√©mantiques.")
        semantic_data = {}
    
    # Mots-cl√©s principaux pour notre th√©saurus. 
    # La cl√© est le mot √† d√©tecter dans le texte, la valeur est le terme √† chercher dans les donn√©es.
    keywords_map = {
        "mariage": "wedding photography",
        "portrait": "portrait photography", 
        "voyage": "travel photography",
        "mode": "fashion photography",
        "noir et blanc": "black and white photography",
        "paysage": "landscape photography",
        "studio": "studio photography",
        "maquilleuse": "makeup",  # Terme plus g√©n√©rique pour HIERTAGS
        "couturiere": "fashion"   # On se rattache √† la mode
    }
    
    final_thesaurus = {}
    priority_counter = 100
    
    for keyword_fr, keyword_en in keywords_map.items():
        print(f"Traitement de '{keyword_fr}' (mapp√© sur '{keyword_en}')")
        base_hashtags = set()
        
        # 1. Trouver les hashtags de base dans les donn√©es scrap√©es
        for category_info in scraped_data:
            if any(term in category_info["category"].lower() for term in keyword_en.split()):
                print(f"  -> Correspondance trouv√©e dans la cat√©gorie scrap√©e : '{category_info['category']}'")
                for tag in category_info["hashtags"]:
                    base_hashtags.add(tag)
        
        # 2. Enrichir avec les donn√©es s√©mantiques de HIERTAGS
        # On cherche le terme le plus simple (ex: "wedding" pour "wedding photography")
        main_semantic_term = keyword_en.split()[0]
        
        if main_semantic_term in semantic_data:
            relations = semantic_data[main_semantic_term]
            # Trier les relations par poids et prendre les 10 meilleures
            top_semantic_tags = sorted(relations.items(), key=lambda item: item[1], reverse=True)[:10]
            print(f"  -> Top 5 tags s√©mantiques de HIERTAGS : {[tag for tag, w in top_semantic_tags[:5]]}")
            
            for tag, weight in top_semantic_tags:
                base_hashtags.add(tag)
        
        # Ajouter le mot-cl√© lui-m√™me s'il est simple
        if len(keyword_fr.split()) == 1:
            base_hashtags.add(keyword_fr.replace(' ', ''))
        
        if base_hashtags:
            final_thesaurus[keyword_fr] = {
                "p": priority_counter,
                "h": sorted(list(base_hashtags))
            }
            priority_counter -= 5  # Diminuer la priorit√© pour le prochain
    
    # Sauvegarde du fichier final
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(final_thesaurus, f, ensure_ascii=False, indent=2)
    
    print(f"\n‚úÖ Th√©saurus final g√©n√©r√© avec succ√®s dans '{output_file}' !")
    print(f"Ce fichier est pr√™t √† √™tre utilis√© dans votre application.")

if __name__ == "__main__":
    generer_thesaurus_final()